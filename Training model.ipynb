{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "371cba30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import uuid\n",
    "import cv2\n",
    "import shutil\n",
    "import albumentations as alb\n",
    "\n",
    "import tensorflow as tf\n",
    "import json\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d8a20c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, Dense, GlobalMaxPooling2D\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "62c9c0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(x): \n",
    "    byte_img = tf.io.read_file(x)\n",
    "    img = tf.io.decode_jpeg(byte_img)\n",
    "    return img\n",
    "\n",
    "def load_labels(label_path):\n",
    "    '''function used to load labels \n",
    "    base on input which is path to file'''\n",
    "    with open(label_path.numpy(), 'r', encoding = \"utf-8\") as f:\n",
    "        label = json.load(f)\n",
    "        \n",
    "    return [label['class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ba9c7795",
   "metadata": {},
   "outputs": [],
   "source": [
    "### loading pretrained CNN model - VGG16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1b5da8",
   "metadata": {},
   "source": [
    "include_top=False configuration exclude the fully connected layers, leaving only the convolutional base of the VGG16 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "332d23b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, None, None, 3)]   0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, None, None, 64)    1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, None, None, 64)    36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, None, None, 64)    0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, None, None, 128)   73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, None, None, 128)   147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, None, None, 128)   0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, None, None, 256)   295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, None, None, 256)   590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, None, None, 256)   590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, None, None, 256)   0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, None, None, 512)   1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, None, None, 512)   0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, None, None, 512)   0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg = VGG16(include_top=False)\n",
    "vgg.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc2c34e",
   "metadata": {},
   "source": [
    "# Loading images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5bcaa6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = tf.data.Dataset.list_files('aug_data4\\\\train\\\\photos\\\\*.jpg', shuffle=False)\n",
    "train_images = train_images.map(load_image)\n",
    "train_images = train_images.map(lambda x: tf.image.resize(x, (120,120)))  # Resize the images to a shape of (120, 120)\n",
    "train_images = train_images.map(lambda x: x/255)                          # Normalize images by dividing each pixel value by 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6737d47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = tf.data.Dataset.list_files('aug_data4\\\\test\\\\photos\\\\*.jpg', shuffle=False)\n",
    "test_images = test_images.map(load_image)\n",
    "test_images = test_images.map(lambda x: tf.image.resize(x, (120,120)))    # Resize the images to a shape of (120, 120)\n",
    "test_images = test_images.map(lambda x: x/255)                            # Normalize images by dividing each pixel value by 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ca67c43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_images = tf.data.Dataset.list_files('aug_data4\\\\val\\\\photos\\\\*.jpg', shuffle=False)\n",
    "val_images = val_images.map(load_image)\n",
    "val_images = val_images.map(lambda x: tf.image.resize(x, (120,120)))     # Resize the images to a shape of (120, 120)\n",
    "val_images = val_images.map(lambda x: x/255)                             # Normalize images by dividing each pixel value by 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "229bd909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.30751637, 0.30751637, 0.29967323],\n",
       "        [0.4362745 , 0.4490196 , 0.45784312],\n",
       "        [0.5035948 , 0.53496736, 0.5428105 ],\n",
       "        ...,\n",
       "        [0.62385625, 0.6552288 , 0.6669935 ],\n",
       "        [0.6245098 , 0.65588236, 0.66764706],\n",
       "        [0.6313726 , 0.67058825, 0.6784314 ]],\n",
       "\n",
       "       [[0.33529413, 0.33333334, 0.3254902 ],\n",
       "        [0.44607842, 0.46372548, 0.45392156],\n",
       "        [0.5281046 , 0.54771245, 0.55947715],\n",
       "        ...,\n",
       "        [0.62941176, 0.6607843 , 0.672549  ],\n",
       "        [0.6362745 , 0.66764706, 0.67941177],\n",
       "        [0.6326799 , 0.667974  , 0.67777795]],\n",
       "\n",
       "       [[0.3156863 , 0.31241828, 0.30457515],\n",
       "        [0.4392157 , 0.4627451 , 0.45882353],\n",
       "        [0.52156866, 0.5529412 , 0.56078434],\n",
       "        ...,\n",
       "        [0.6333333 , 0.66862744, 0.6745098 ],\n",
       "        [0.6362745 , 0.66764706, 0.6754902 ],\n",
       "        [0.63529414, 0.6666667 , 0.6745098 ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.47026145, 0.52516335, 0.55457515],\n",
       "        [0.46862745, 0.527451  , 0.55490196],\n",
       "        [0.47843137, 0.5294118 , 0.56078434],\n",
       "        ...,\n",
       "        [0.31241813, 0.26143774, 0.23790833],\n",
       "        [0.31470588, 0.25588235, 0.23235294],\n",
       "        [0.3326799 , 0.27385637, 0.2464054 ]],\n",
       "\n",
       "       [[0.4751634 , 0.53006536, 0.55947715],\n",
       "        [0.46764705, 0.5264706 , 0.55196077],\n",
       "        [0.47058824, 0.52156866, 0.54509807],\n",
       "        ...,\n",
       "        [0.31274498, 0.2617646 , 0.23823518],\n",
       "        [0.30784315, 0.25      , 0.22058824],\n",
       "        [0.32222205, 0.2673201 , 0.23202598]],\n",
       "\n",
       "       [[0.49313724, 0.54019606, 0.5637255 ],\n",
       "        [0.4764706 , 0.527451  , 0.5509804 ],\n",
       "        [0.4745098 , 0.5254902 , 0.54901963],\n",
       "        ...,\n",
       "        [0.30980393, 0.2647059 , 0.23137255],\n",
       "        [0.3107843 , 0.25784314, 0.22058824],\n",
       "        [0.32352942, 0.25882354, 0.21372549]]], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc45042f",
   "metadata": {},
   "source": [
    "# Loading labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e640d127",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = tf.data.Dataset.list_files('aug_data4\\\\train\\\\labels\\\\*.json', shuffle=False)  # Create a dataset containing file paths to the JSON label files\n",
    "train_labels = train_labels.map(lambda x: tf.py_function(load_labels, [x], [tf.uint8]))       # Use the `map` function to apply a load_labels function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2547a0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = tf.data.Dataset.list_files('aug_data4\\\\test\\\\labels\\\\*.json', shuffle=False) # Create a dataset containing file paths to the JSON label files\n",
    "test_labels = test_labels.map(lambda x: tf.py_function(load_labels, [x], [tf.uint8]))      # Use the `map` function to apply a load_labels function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "29adb5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_labels = tf.data.Dataset.list_files('aug_data4\\\\val\\\\labels\\\\*.json', shuffle=False) # Create a dataset containing file paths to the JSON label files\n",
    "val_labels = val_labels.map(lambda x: tf.py_function(load_labels, [x], [tf.uint8]))      # Use the `map` function to apply a load_labels function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ae0d77",
   "metadata": {},
   "source": [
    "# test, train and validation data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d9be51b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = tf.data.Dataset.zip((train_images, train_labels))  # Combine the train_images and train_labels\n",
    "train = train.shuffle(5000)                                # Shuffle the elements of the train dataset randomly\n",
    "train = train.batch(8)                                     # Group the elements of the train dataset into batches of size 8\n",
    "train = train.prefetch(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e9595e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = tf.data.Dataset.zip((test_images, test_labels))     # Combine the test_images and test_labels\n",
    "test = test.shuffle(1300)                                  # Shuffle the elements of the test dataset randomly\n",
    "test = test.batch(8)                                       # Group the elements of the test dataset into batches of size 8\n",
    "test = test.prefetch(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "161f7dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "val = tf.data.Dataset.zip((val_images, val_labels))        # Combine the val_images and val_labels\n",
    "val = val.shuffle(1000)                                    # Shuffle the elements of the val dataset randomly\n",
    "val = val.batch(8)                                         # Group the elements of the val dataset into batches of size 8\n",
    "val = val.prefetch(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a1c958",
   "metadata": {},
   "source": [
    "# Building model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "142f0d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(): \n",
    "    input_layer = Input(shape=(120,120,3))                        # Define the input layer with a shape of (120, 120, 3)\n",
    "                                                                  # This specifies the expected shape of the input images\n",
    "    \n",
    "    vgg = VGG16(include_top=False)(input_layer)                   # Create the convolutional base of the model using VGG16\n",
    "\n",
    "    # Classification Model  \n",
    "    f1 = GlobalMaxPooling2D()(vgg)                                # Apply global max pooling to the output of the VGG16 model\n",
    "    class1 = Dense(2048, activation='relu')(f1)                   # Add a dense layer with 2048 units and ReLU activation\n",
    "    class2 = Dense(1, activation='sigmoid')(class1)               # Add a dense layer with 1 unit and sigmoid activation\n",
    "    \n",
    "    \n",
    "    fist_tracker = Model(inputs = input_layer, outputs=[class2])  # Create a model that takes input from the input_layer and outputs the class2 predictions\n",
    "\n",
    "    return fist_tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1fe115a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fist_tracker = build_model()         # Create the `fist_tracker` model by calling the `build_model` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "39e9c577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 120, 120, 3)]     0         \n",
      "                                                                 \n",
      " vgg16 (Functional)          (None, None, None, 512)   14714688  \n",
      "                                                                 \n",
      " global_max_pooling2d_1 (Glo  (None, 512)              0         \n",
      " balMaxPooling2D)                                                \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2048)              1050624   \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 2049      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15,767,361\n",
      "Trainable params: 15,767,361\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "fist_tracker.summary()               # Print a summary of the `fist_tracker` model's architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6d9d6093",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33333333333333326"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches_per_epoch = len(train)            # Calculate the number of batches per epoch\n",
    "initial_learning_rate = 0.0001            # Set the initial learning rate to 0.0001\n",
    "lr_decay = (1./0.75 -1)                   # Calculate the learning rate decay factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fd37195f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a learning rate schedule using ExponentialDecay\n",
    "# This schedule will decrease the learning rate over time in an exponential manner\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(   \n",
    "    initial_learning_rate,\n",
    "    decay_steps = batches_per_epoch,\n",
    "    decay_rate=lr_decay,\n",
    "    staircase=True)\n",
    "\n",
    "# Create an Adam optimizer with the specified learning rate schedule\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=lr_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c126717e",
   "metadata": {},
   "outputs": [],
   "source": [
    "classloss = tf.keras.losses.BinaryCrossentropy()    # Create a binary cross-entropy loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0d70884d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FistTracker(Model): \n",
    "    def __init__(self, fisttracker,  **kwargs):  # The fisttracker argument represents the pre-built model passed to the class\n",
    "        super().__init__(**kwargs)\n",
    "        self.model = fisttracker                 # The model is assigned to the 'self.model' attribute\n",
    "        \n",
    "\n",
    "    def compile(self, opt, classloss, **kwargs):\n",
    "        super().compile(**kwargs)                # Configure the model for training\n",
    "        self.closs = classloss                   # The classloss argument represents the loss function used for training\n",
    "        self.opt = opt                           # The opt argument represents the optimizer used for training\n",
    "        \n",
    "    \n",
    "    def train_step(self, batch, **kwargs): \n",
    "        X, y = batch                             # Retrieve the input features 'X' and target labels 'y' from the batch\n",
    "        \n",
    "        with tf.GradientTape() as tape: \n",
    "            classes = self.model(X, training=True)   # Set training=True to enable training-specific behavior e.g., applying dropout\n",
    "            total_loss = self.closs(y[0], classes)   # Calculate the total loss using the provided loss function 'self.closs'\n",
    "            grad = tape.gradient(total_loss, self.model.trainable_variables)  # Compute the gradients of the total loss\n",
    "\n",
    "        opt.apply_gradients(zip(grad, self.model.trainable_variables))        # Update the model's trainable variables\n",
    "        return {\"total_loss\":total_loss}\n",
    "    \n",
    "    def test_step(self, batch, **kwargs): \n",
    "        X, y = batch\n",
    "        \n",
    "        classes = self.model(X, training=False)  # Forward pass: obtain the predicted classes using the model\n",
    "        total_loss = self.closs(y[0], classes)   # Calculate the total loss using the provided loss function 'self.closs'\n",
    "\n",
    "        return {\"total_loss\":total_loss}\n",
    "        \n",
    "    def call(self, X, **kwargs):                 # This method forwards the input 'X' through the model and returns the output\n",
    "        return self.model(X, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a2be9e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FistTracker(fist_tracker)     # The fist_tracker model is passed as an argument to initialize the FistTracker class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cf5d1db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(opt, classloss)         # Compile the model for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "26ea16d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir='logs'                         # Define the directory path where the TensorBoard logs will be saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b5b2f861",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir) # The 'log_dir' parameter specifies the directory path where the logs will be saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4cbbe442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "105/105 [==============================] - 274s 3s/step - total_loss: 0.5992 - val_total_loss: 0.8469\n",
      "Epoch 2/4\n",
      "105/105 [==============================] - 277s 3s/step - total_loss: 0.3991 - val_total_loss: 0.7421\n",
      "Epoch 3/4\n",
      "105/105 [==============================] - 282s 3s/step - total_loss: 0.1614 - val_total_loss: 6.8578e-05\n",
      "Epoch 4/4\n",
      "105/105 [==============================] - 286s 3s/step - total_loss: 0.0685 - val_total_loss: 0.1509\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(train, epochs = 4, validation_data = val, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0db78413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "fist_tracker.save('fist_tracker_aug4_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "847d42e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "facetracker = load_model('fist_tracker_aug4_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "548f8c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 10532), started 0:01:12 ago. (Use '!kill 10532' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-b282c5049b73a3a9\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-b282c5049b73a3a9\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cd34b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
